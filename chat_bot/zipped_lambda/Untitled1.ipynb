{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from botocore.vendored import requests\n",
    "import ccxt\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import boto3\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# s3 = boto3.client('s3')\n",
    "\n",
    "def parse_float(n):\n",
    "    \"\"\"\n",
    "    Securely converts a non-numeric value to float.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return float(n)\n",
    "    except ValueError:\n",
    "        return \"error\"\n",
    "    \n",
    "\n",
    "    \n",
    "def risk_assay(bday, income, amount, risk, retire):\n",
    "    '''from the clients inputs we are going to assign them a risk score high risk=2, moderate risk=2, low risk=1'''\n",
    "\n",
    "    rlst=[]\n",
    "    birth_date = datetime.strptime(bday, \"%Y-%m-%d\")\n",
    "    age = relativedelta(datetime.now(), birth_date).years\n",
    "    working_age=retire-age\n",
    "    income_ratio=income/amount\n",
    "    \n",
    "    '''we are going to use their age and retirement age to create a risk value, closer to retirement, the higher the risk'''\n",
    "\n",
    "    if working_age<17:\n",
    "        rlst.append(3)\n",
    "    elif working_age>=17 and working_age<34:\n",
    "        rlst.append(2)\n",
    "    else:\n",
    "        rlst.append(1)\n",
    "        \n",
    "    '''we will use their income and amount to invest.  If the investment amount is a sizable chunk of their annual income\n",
    "    we will say it is higher risk'''\n",
    "    if income_ratio<2:\n",
    "        rlst.append(3)\n",
    "    elif income_ratio>=2 and income_ratio<5:\n",
    "        rlst.append(2)\n",
    "    else:\n",
    "        rlst.append(1)\n",
    "        \n",
    "    '''we will use their explicitly stated risk as an input also,  if they entered giberish, we will ask them for clarification'''\n",
    "    if risk.lower()=='high':\n",
    "        rlist.append(3)\n",
    "    elif risk.lower()=='high':\n",
    "        rlst.append(2)\n",
    "    elif risk.lower()=='low':\n",
    "        rlst.append(1)\n",
    "        \n",
    "    ave_risk = round(sum(rlst) / len(rlst),0)\n",
    "    \n",
    "    return(ave_risk)\n",
    "\n",
    "\n",
    "\n",
    "def get_coins():\n",
    "#     '''here we read the coins csv file from the E3 drive and pass it back'''\n",
    "#     bucket = 'ft-project2'\n",
    "#     key = 'Classification.csv'\n",
    "#     data = s3.get_object(Bucket=bucket, Key=key)\n",
    "#     df=pd.read_csv(data)\n",
    "    data=Path('Classification.csv')\n",
    "    df=pd.read_csv(data)\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "\n",
    "\n",
    "def get_tickers(ave_risk, coin_df):\n",
    "    '''we are saying cryto class have a risk associated with them and based \n",
    "    on the risk metric for the client we are assigning them one of those risk \n",
    "    portfolios'''\n",
    "    tickers=[]\n",
    "    if ave_risk==1:\n",
    "        symbols=df['symbol'].loc[(coin_df['class']==2)|(coin_df['class']==0)].to_list()\n",
    "    elif ave_risk==2:\n",
    "        symbols=coin_df['symbol'].to_list()\n",
    "    elif ave_risk==3:\n",
    "        symbols=coin_df['symbol'].loc[(coin_df['class']==1)|(coin_df['class']==0)].to_list()\n",
    " \n",
    "    return(symbols)\n",
    "\n",
    "\n",
    "\n",
    "def get_portfolio(symbols):\n",
    "    i=0\n",
    "    exchange = ccxt.kraken({\n",
    "    'apiKey': KRAKEN_API_KEY,\n",
    "    'secret': KRAKEN_SECRET_API_KEY,\n",
    "    })\n",
    "    since = exchange.parse8601('2018-01-01T00:00:00z')\n",
    "\n",
    "    for symbol in symbols:\n",
    "        if i==0:\n",
    "            try:\n",
    "                data = exchange.fetchOHLCV(symbol,'1d', since, params = {})\n",
    "                header = ['Date', 'Open', 'High', 'Low', symbol, 'Volume']\n",
    "                ticker_df = pd.DataFrame(data, columns=header)\n",
    "                ticker_df['Date']=pd.to_datetime(ticker_df.Date/1000, unit='s')\n",
    "                ticker_df.set_index('Date', inplace=True)\n",
    "                ticker_df.drop(columns=['Open', 'High', 'Low', 'Volume'], inplace=True)\n",
    "                i+=1\n",
    "            except:\n",
    "                continue\n",
    "        else:\n",
    "            try:\n",
    "                data = exchange.fetchOHLCV(symbol,'1d', since, params = {})\n",
    "                header = ['Date', 'Open', 'High', 'Low', symbol, 'Volume']\n",
    "                df = pd.DataFrame(data, columns=header)\n",
    "                df['Date']=pd.to_datetime(df.Date/1000, unit='s')\n",
    "                df.set_index('Date', inplace=True)\n",
    "                df.drop(columns=['Open', 'High', 'Low', 'Volume'], inplace=True)\n",
    "                ticker_df=pd.concat([ticker_df, df], axis=1, join='inner')\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    return(ticker_df)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def make_data_df(coin_df, tickers_df, asset_returns, symbols):\n",
    "    tickers=tickers_df.columns.tolist()\n",
    "    data_df=pd.DataFrame()\n",
    "    data_df['tickers']=tickers\n",
    "    data_df['returns']=asset_returns\n",
    "    data_df.set_index('tickers', inplace=True)\n",
    "    data_df['mrkcap']=0\n",
    "    data_df['price']=0\n",
    "\n",
    "    clean_tickers, data_df=fill_data_df(coin_df, data_df, tickers_df, tickers)\n",
    "    tickers_df=prune_tickers_df(tickers,clean_tickers, tickers_df)\n",
    "    return(clean_tickers, data_df, tickers_df)\n",
    "\n",
    "\n",
    "def fill_data_df(coin_df,data_df, tickers_df, tickers):\n",
    "    last_price=tickers_df.iloc[-1,:]\n",
    "    for ticker in tickers:\n",
    "        data_df.loc[ticker,'mrkcap']=coin_df.loc[ticker,'Market_Cap']\n",
    "        data_df.loc[ticker,'price']=last_price.loc[ticker]\n",
    "    data_df.dropna(inplace=True)\n",
    "    clean_tickers=data_df.index.to_list()\n",
    "        \n",
    "    return(clean_tickers, data_df)\n",
    "\n",
    "def prune_tickers_df(tickers_old, tickers_new, tickers_df):\n",
    "    for ticker in tickers_old:\n",
    "        if ticker not in tickers_new:\n",
    "            tickers_df.drop([ticker], axis=1, inplace=True)\n",
    "    return(tickers_df)\n",
    "\n",
    "def make_port_df(weights_df, clean_tickers, data_dfl, tickers_df, amount):\n",
    "    port_df=weights_df.loc[weights_df[0]>0]\n",
    "    port_df=port_df/port_df[0].sum()\n",
    "    port_df.columns=['weights']\n",
    "    port_df['price']=0\n",
    "    port_df['returns']=0\n",
    "    port_df['shares']=0\n",
    "    port_df['value']=0\n",
    "\n",
    "    \n",
    "    return (fill_port_df(clean_tickers, port_df, data_df, tickers_df,amount))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def fill_port_df(clean_tickers, port_df, data_df, tickers_df,amount):\n",
    "\n",
    "    port_tickers=port_df.index.to_list()\n",
    "    tickers_df=prune_tickers_df(clean_tickers, port_tickers, tickers_df)\n",
    "    last_price=tickers_df.iloc[-1,:]\n",
    "    last_price.columns=['price']\n",
    "    for ticker in port_tickers:\n",
    "        port_df.loc[ticker,'price']=last_price.loc[ticker]\n",
    "        port_df.loc[ticker,'returns']=data_df.loc[ticker,'returns']\n",
    "        port_df.loc[ticker,'shares']=(amount*port_df.loc[ticker, 'weights']//port_df.loc[ticker, 'price'])\n",
    "        port_df.loc[ticker,'value']=(port_df.loc[ticker, 'shares']*port_df.loc[ticker, 'price'])  \n",
    "    left=amount-port_df['value'].sum()\n",
    "    \n",
    "    return(left, port_df, port_tickers)\n",
    "\n",
    "\n",
    "def make_port_metrics(port_df, tickers_df):\n",
    "    wts=port_df['weights'].to_list()\n",
    "    wts=np.asarray(wts)\n",
    "    port_ret=tickers_df.pct_change()\n",
    "    port_ret.dropna(inplace=True)\n",
    "    port_ret['return']=port_ret.mul(wts,axis=1).sum(axis=1)\n",
    "    ann_ret=port_ret['return'].mean()* 252-.0062\n",
    "    \n",
    "    cov_matrix = port_ret.iloc[:,0:-1].cov()\n",
    "    ann_port_std=round(((np.sqrt(np.dot(wts.T,np.dot(cov_matrix, wts)))* np.sqrt(252))),6)\n",
    "    sharpe=ann_ret/ann_port_std\n",
    "    \n",
    "    metrics=[ann_ret, sharpe, ann_port_std]\n",
    "    \n",
    "    \n",
    "    return (metrics)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''This block of code is the Black Litterman portfolio functions, thy pyprotfolioopt, library I wanted to use would not compile on EC2.\n",
    "this code was derived from https://github.com/overney/python/blob/master/Black%20Litterman%20Model.ipynb, and does not have the optimization \n",
    "that the other library achieved'''\n",
    "\n",
    "def in_return_cov(df): \n",
    "    '''calculating the annual returns for each assset and generating a covariance matrix of the returns'''\n",
    "    price = df.pct_change()\n",
    "    price.iloc[0,:] = 0    \n",
    "    \n",
    "    returns = np.matrix(price)\n",
    "    mean_returns = np.mean(returns, axis = 0)\n",
    "    \n",
    "    annual_returns = np.array([])\n",
    "    for i in range(len(np.transpose(mean_returns))):\n",
    "        annual_returns = np.append(annual_returns,(mean_returns[0,i]+1)**252-1)   \n",
    "    \n",
    "    cov = price.cov()*252\n",
    "    \n",
    "    return (annual_returns, np.matrix(cov))\n",
    "\n",
    "\n",
    "def port_return(W,r):\n",
    "    return sum(W*r)\n",
    "\n",
    "\n",
    "def mkt_weights(weights):\n",
    "    return np.array(weights) / sum(weights)\n",
    "\n",
    "def risk_return(W,S,r,rf=0.0063):\n",
    "    var = np.dot(np.dot(W,S),np.transpose(W))\n",
    "    port_r = port_return(W,r)\n",
    "    return np.ndarray.item((port_r - rf) / var)\n",
    "\n",
    "def vector_equilibrium_return(S, W, r ):\n",
    "    \n",
    "    A = risk_return(W,S,r)\n",
    "    \n",
    "    return (np.dot(A,np.dot(S,W)))\n",
    "\n",
    "def diago_omega(t, P, S):\n",
    "    \n",
    "    omega = np.dot(t,np.dot(P,np.dot(S,np.transpose(P))))\n",
    "    \n",
    "    for i in range(len(omega)):\n",
    "        for y in range(len(omega)):\n",
    "            if i != y: omega[i,y] = 0\n",
    "    return omega\n",
    "\n",
    "def make_view_matrix(clean_tickers, data_df):\n",
    "    N=len(clean_tickers)\n",
    "    Q = np.zeros((N,1))\n",
    "    P = np.zeros((N,N))\n",
    "    for n in range(len(clean_tickers)):\n",
    "        P[n,n]=1\n",
    "        Q[n,0]=data_df.iloc[n,0]\n",
    "    return(P, Q)\n",
    "    \n",
    "def posterior_estimate_return(t,S,P,Q,PI):\n",
    "    \n",
    "    omega = diago_omega(t, P, S)\n",
    "    \n",
    "    parte_1 = t*np.dot(S,np.transpose(P))\n",
    "    parte_2 = np.linalg.inv(np.dot(P*t,np.dot(S,np.transpose(P))) + omega)\n",
    "    parte_3 = Q - np.dot(P,np.transpose(PI))\n",
    "    \n",
    "    return np.transpose(PI) + np.dot(parte_1,np.dot(parte_2,parte_3))\n",
    "\n",
    "def posterior_covariance(t,S,P,PI):\n",
    "    \n",
    "    omega = diago_omega(t, P, S)\n",
    "    \n",
    "    parte_1 = t*np.dot(S,np.transpose(P))\n",
    "    parte_2 = np.linalg.inv(t*np.dot(P,np.dot(S,np.transpose(P)))+omega)\n",
    "    parte_3 = t*np.dot(P,S)\n",
    "\n",
    "    return t*S - np.dot(parte_1,np.dot(parte_2,parte_3))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''Here we package the lambda functions response and send it back to the client'''\n",
    "\n",
    "def make_output (port_df, left, amount, metrics, port_tickers):\n",
    "    '''Here we are making the text output for the chatbot, it will give all the metrics for the optimized portfolio'''\n",
    "    port_str=''\n",
    "\n",
    "    for ticker in port_tickers:\n",
    "        str=(f' {int(port_df.loc[ticker, \"shares\"])} shares of {ticker} worth ${port_df.loc[ticker,\"value\"]:.2f},\\n')\n",
    "        port_str=port_str+str\n",
    "\n",
    "    out_str=(f'''For your ${amount} investment, we have calculated the most afficient portfolio for your level of risk will be\n",
    "    {port_str[:-3]} \n",
    "    and you will have ${left:.2f} leftover.\n",
    "    This portfolio has a current annualized return of {metrics[0]*100:.2f}%, voluntility of {metrics[2]:.2f}, and a sharp raio of {metrics[1]:.2f}''')\n",
    "    \n",
    "    return(out_str)\n",
    "\n",
    "\n",
    "\n",
    "def close(bday, session_attributes, fulfillment_state, message):\n",
    "    '''this packages up the full JSON response back to the chatbot'''\n",
    "    response = {\n",
    "        'sessionAttributes': session_attributes,\n",
    "        'dialogAction': {\n",
    "            'type': 'Close',\n",
    "            'fulfillmentState': fulfillment_state,\n",
    "            'message': message\n",
    "        }\n",
    "    }\n",
    "    return response\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_slots(intent_request):\n",
    "    \"\"\"\n",
    "    Fetch all the slots and their values from the current intent.\n",
    "    \"\"\"\n",
    "    return intent_request[\"currentIntent\"][\"slots\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_request={\n",
    "  \"messageVersion\": \"1.0\",\n",
    "  \"invocationSource\": \"DialogCodeHook\",\n",
    "  \"userId\": \"John\",\n",
    "  \"sessionAttributes\": {},\n",
    "  \"bot\": {\n",
    "    \"name\": \"coinBot\",\n",
    "    \"alias\": \"$LATEST\",\n",
    "    \"version\": \"$LATEST\"\n",
    "  },\n",
    "  \"outputDialogMode\": \"Text\",\n",
    "  \"currentIntent\": {\n",
    "    \"name\": \"coinBot\",\n",
    "    \"slots\": {\n",
    "      \"bday\": \"1980-01-01\",\n",
    "      \"retire\": \"76\",\n",
    "      \"income\": \"1000000\",\n",
    "      \"risk\": \"low\",\n",
    "      \"amount\": \"1000000\"\n",
    "    },\n",
    "    \"confirmationStatus\": \"None\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    '''Unpack the inputs from the chatbot'''\n",
    "bday = get_slots(intent_request)[\"bday\"]\n",
    "amount = parse_float(get_slots(intent_request)[\"amount\"])\n",
    "retire =parse_float( get_slots(intent_request)[\"retire\"])\n",
    "risk = get_slots(intent_request)[\"risk\"]\n",
    "income =parse_float(get_slots(intent_request)[\"income\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    \n",
    "'''we will assess the clients risk adversion pull the csv for the crypto dataframe,\n",
    "create their portfolio, and optimize it'''\n",
    "client_risk=risk_assay(bday, income, amount, risk, retire)\n",
    "coin_df=get_coins()\n",
    "symbols=get_tickers(client_risk, coin_df)\n",
    "coin_df.set_index('symbol', inplace=True)\n",
    "tickers_df=get_portfolio(symbols)\n",
    "tickers=tickers_df.columns.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Here we start the Black Litterman model, It needs better optimization'''\n",
    "asset_returns , S= in_return_cov(tickers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tickers, data_df, tickers_df=make_data_df(coin_df, tickers_df, asset_returns, tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_returns , S= in_return_cov(tickers_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = mkt_weights(data_df['mrkcap'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = risk_return(W,S,data_df['returns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PI = vector_equilibrium_return(S, W, data_df['returns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "P, Q=make_view_matrix(clean_tickers, data_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 1 / len(tickers_df)\n",
    "expc_return = posterior_estimate_return(t,S,P,Q,PI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_cov = posterior_covariance(t,S,P,PI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_post_estimate = post_cov + S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weight = np.dot(np.transpose(expc_return),np.linalg.inv(A*cov_post_estimate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_df=pd.DataFrame(new_weight, columns = clean_tickers).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''using the weights we will allocate their investment'''\n",
    "left, port_df, port_tickers=make_port_df(weights_df, clean_tickers, data_df, tickers_df, amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=make_port_metrics(port_df, tickers_df)\n",
    "output_message=make_output(port_df, left, amount, metrics, port_tickers)\n",
    "lambda_str=close(bday, intent_request[\"sessionAttributes\"], \"Fulfilled\", output_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
